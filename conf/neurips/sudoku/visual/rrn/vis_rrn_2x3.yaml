seed_everything: 42

data:
  class_path: src.datasets.SudokuDataModule
  init_args:
    data_path: data/sudoku_2x3_11214.pt
    collate_fn: src.rrn_utils.collate_sudoku_graph
    splits:
      train: 10000
      val: 200 
      test: 1000
    num_validate_train: 10
    batch_sizes:
      train: 10
      val: 100
      test: 100
    num_workers: 0
    mnist_dir: data/mnist
model:
  class_path: src.neural_models.SudokuNNModel
  init_args:
    num_classes: 6
    x_key: query/img
    y_key: target/bit
    c_encoder:
      class_path: src.encoders.VisSudokuCEncoderForRRN
      init_args:
        classifier:
          class_path: src.encoders.LeNet
          init_args:
            num_classes: 7
 
    network:
      class_path:  src.neural_models.SudokuNN
      init_args:
        num_steps: 24 
        embed_size: 16
        hidden_dim: 96
        edge_drop: 0.1
        num_classes: 6

    optimizer:
      class_path: torch.optim.AdamW
      init_args:
        lr: 1.0e-3
        weight_decay: 0.0

    lr_scheduler:
      # class_path: torch.optim.lr_scheduler.CyclicLR
      # init_args:
      #   base_lr: 0.0
      #   max_lr: 1.0e-3
      #   step_size_up: 1000
      #   cycle_momentum: false
      # config:
      #   interval: step

      class_path: torch.optim.lr_scheduler.ExponentialLR
      init_args:
        gamma: 1.0

      # class_path: torch.optim.lr_scheduler.ReduceLROnPlateau
      # init_args:
      #   mode: max
      #   factor: 0.3
      #   patience: 100
      #   min_lr: 0.000001
      # config:
      #   monitor: train/acc/bit_acc
      #   interval: step

    schedulers:
      "temp":
        class_path: torch.optim.lr_scheduler.ExponentialLR
        init_args:
          gamma: 1.0

        # class_path: torch.optim.lr_scheduler.ReduceLROnPlateau
        # init_args:
        #   mode: max
        #   factor: 0.1
        #   patience: 1000
        # config:
        #   monitor: acc
        #   interval: step
        # init: 1.0

skip_initial_validation: True
trainer:
  max_epochs: 1000
  min_epochs: 50
  callbacks:
  - class_path: pytorch_lightning.callbacks.EarlyStopping
    init_args:
      monitor: val/acc/all
      patience: 10
      mode: max
  - class_path: pytorch_lightning.callbacks.ModelSummary
    init_args:
      max_depth: -1
  - class_path: pytorch_lightning.callbacks.LearningRateMonitor
    init_args:
      logging_interval: step
  - class_path: pytorch_lightning.callbacks.ModelCheckpoint
    init_args:
      monitor: 'val/acc/all'
      mode: 'max'
      filename: best

  - class_path: pytorch_lightning.callbacks.ModelCheckpoint
    init_args:
      save_last: True
      save_on_train_epoch_end: True

  log_every_n_steps: 10
  check_val_every_n_epoch: 1
  logger:
    class_path: pytorch_lightning.loggers.TensorBoardLogger
    init_args:
      save_dir: hpc_runs/sudokuV2/rrn/
      name: vis2x3_wgradclip
      default_hp_metric: false
  gradient_clip_val: 5.0
  gpus: 1
  auto_select_gpus: true
  #precision: 16
  num_sanity_val_steps: 0
  reload_dataloaders_every_n_epochs: 0
 # detect_anomaly: true
